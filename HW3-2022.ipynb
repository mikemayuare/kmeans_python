{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Data Science 2022\n",
    "## Homework Assigment Three\n",
    "\n",
    "Homework Assigment Three focus in the step-by-step implementation of a simple, yet popular, clustering algorithm, the K-Means. Although in most projects you will source algorithms from readily available in implementations found in libraries such as scikit-learn or Keras, in some cases you will need to implement an algorithm yourself. For instance, if such algorithm is not available or if you want to implement a problem-specific modification. In that sense, learning to implement algorithms is an important part of your skillset.\n",
    "\n",
    "Your submission will be graded according to the following guidelines:\n",
    "1. **Execution** (does your program does what is asked from the exercise?\n",
    "2. **Objectivity** (are you using the adequate libraries? are you using a library ... )\n",
    "3. **Readibility** of your code (that includes comments, naming of variables, supporting text, etc ...)\n",
    "\n",
    "In some questions might require that you make critical decisions, or design choices. In such cases, you will be graded according to your ability to justify and support your decisions.\n",
    "\n",
    "<b>Comment your code properly, which includes naming your variables in a meaningful manner. Badly documented code will be penalized.</b>\n",
    "\n",
    "This assignment is to be done in pairs, as in the first one, but remember that **you can't have the same pair as you had in Homeworks 1 and 2**. \n",
    "\n",
    "**Students that are caught cheating will obtain a score of 0 points.** <br>\n",
    "\n",
    "The Homework 3 is worth 30% of your final grade.    \n",
    "\n",
    "The submission package should correspond to a .zip archive (.rar files are not accepted) with the following files:\n",
    "1. Jupyter Notebook with the output of all the cells;\n",
    "2. PDF/HTML print of your Jupyter Notebook (in jupyter go to File -> Download as -> HTML/PDF);\n",
    "3. All text or .csv files exported as part of the exercises. Do not upload the files downloaded/imported as part of the exercises.\n",
    "\n",
    "**Please change the name of the notebook to \"H2.\\<student_1_id\\>_\\<student_2_id\\>.ipynb\", replacing \\<student_id\\> by your student_id.** <br>\n",
    "\n",
    "Submission is done through the respective Moodle activity and only one of the group members has to submit the files. <br>\n",
    "Deadline is the 30th of October at 23:59. <br>\n",
    "A penality of 1 point per day late will be applied to late deliveries. <br>\n",
    "**In this notebook you are allowed to use Pandas and Numpy.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Registration\n",
    "\n",
    "Edit this cell with the information of the authors of this submission.\n",
    "\n",
    "|      |     Student Name     |     Student ID     | \n",
    "|---   |         ---          |           ---          |\n",
    "| 1    |      XXXXXXXX        |       XXXXXXXX         | \n",
    "| 2    |      XXXXXXXX        |       XXXXXXXX         | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with K-Means\n",
    "\n",
    "K-means is one of the simplest clustering algorithms, which you perhaps are already familiar from Data Mining. The K-means Algorithm consists in writing a program that proceeds as follows:\n",
    "\n",
    "1. Choose value for K (number of clusters);\n",
    "2. Initialize the locations of the centroids, which we can do by randomly select K points from your dataset as initial locations of the centroids;\n",
    "3. Calculate distance of all other points to each of the K centroids;\n",
    "4. Associate each point to the cluster of the closest centroid;\n",
    "5. Update the centroid position, by computing the average coordinates of all points associated to each cluster;\n",
    "6. Evaluate the average change in the centroids positions, as a measure of convergence (the algorithm is said to have converged to the solution when the positions of the centroids don't change more than a given tolerance threshold);\n",
    "7. Repeat steps 3-6 until either the centroids no longer move more than a tolerance threshold or until you repeated these steps at least for specified number of iterations (niter)\n",
    "\n",
    "The algorithm is thus parametized by the number of clusters (K), the maximum number of iterations (niter), and the tolerance threshold (tol).\n",
    "\n",
    "### Step 1\n",
    "\n",
    "Let us start by importing the necessary libraries to execute this homework. <br>\n",
    "Import **numpy, Scipy, and pandas** using, respectively, the **aliases np, sc, and pd**.\n",
    "\n",
    "<span style=\"color:red\">**These are the only libraries you are allowed to use in the remaining of the steps, unless explicitly said the opposite/if the library is imported in the cells below.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that we devise a strategy to test our code at each step, in order to assess if it performs as expected. To that end, we have split each step of the algorithm in different blocks, and we ask you to test each block against a simple scenario where the outcome is predictable and can be computed by hand. In some steps, however, we want to pass a more comprehensive data set with similar properties to the real dataset we will be working with.<br>\n",
    "\n",
    "Such test datasets try to create realistic conditions in which your algorithm is expected to work correctly, and for which we can also assess if the solution matches our expectation and have a general understanding if the algorithm performs as expected in \"real-world\" conditions.<br>\n",
    "\n",
    "For this homework we will resort to a dataset that contains two clearly distinct clusters. We generated the clusters by sampling points from two distinct gaussian distributions with different averages and same standard deviation. <br>\n",
    "\n",
    "As such, our algorithm should be able to identify each cluster easily, and place the centroids close to the averages of the two distributions. <br>\n",
    "\n",
    "Run the cell below to download, load the data into a numpy array, and visualize your Test dataset.<br>\n",
    "You will run your algorithm implementation against this dataset as a proof of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# download the file into a dataframes and convert it to a numpy array.\n",
    "data_test = pd.read_csv(\"https://www.dropbox.com/s/gax1l68jsarxqt9/data_test.txt?dl=1\", header=None).to_numpy()\n",
    "\n",
    "#plot the points into a scatter plot\n",
    "plt.scatter(data_test[:, 0], data_test[:,1], color ='k', marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 \n",
    "\n",
    "Write a function named <b>init</b> that takes two arguments: $points$ and $K$. <br>\n",
    "The function <b>init</b> should return a numpy ndarray with  $K$ elements sampled randomly and without replacement from $points$. Meaning, the same point should not be picked up twice. <br>\n",
    "\n",
    "**Show that your function performs as desired by calling it with** $K = 2$ **and on the data_test as the** $points$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Write a function named <b>distance</b> that takes two arguments: $p1$ and $p2$. <br>\n",
    "The function <b>distance</b> should return a scalar that corresponds to the euclidian distance between points $p1$ and $p2$, that should have a ndarray format. <br> \n",
    "For the assignment you can assume that $p1$ and $p2$ are two-dimensional ndarrays points. But in general, you should assume that p1 and p2 are two ndarrays of the same size.\n",
    "\n",
    "Recall that the euclidian distance (d) between two points ($p_1$ and $p_2$) in a 2-dimensional space is given by:<br><br>\n",
    "\\begin{equation}\n",
    "    d(p_1, p_2) = \\sqrt{(x_1-x_2)^2 + (y_1-y_2)^2}\n",
    "\\end{equation}<br>\n",
    "where $p_1 = \\{x_1,y_1\\}$ and  $p_2 = \\{x_2,y_2\\}$. \n",
    "\n",
    "**Test your function works by computing the distance between p1=(1,3) and p2=(7,2), which is $\\approx$ 6.08.**<br>\n",
    "**Consider using the existing Numpy or Scipy packages for this task**\n",
    "\n",
    "Can you write a function that computes the euclidian distance between two points of arbitrary dimension? <br>\n",
    "In general, for arbitrary dimensionality the square of the distance can be computed as:<br><br>\n",
    "\\begin{equation}\n",
    "    d^2(p_1, p_2) = \\sum_{i=0}^{D-1} (x_i-y_i)^2\n",
    "\\end{equation}<br>\n",
    "where $p_1 = \\{x_1,x_2,...,x_{D-1}, x_D\\}$ and $p_2 = \\{y_1,y_2,...,y_{D-1},y_D\\}$.<br>\n",
    "\n",
    "**Show your function works by computing the distance between (1,3,-9,12) and (7,2,0,5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test variables do not change\n",
    "p1 = np.array([1,3])\n",
    "p2 = np.array([7,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Write a function named <b>centroid</b> that takes one argument: $points$.<br>\n",
    "\n",
    "The argument $points$ should be a ndarray with the coordinates of a set of observations.<br>\n",
    "\n",
    "The function <b>centroid</b> should return an ndarray with $d$ values (being $d$ the number of dimensions)</span>, the $n^{th}$ index of the returned output ndarray should thus correspond to the averaged of the values in the $n^{th}$ column of the points ndarray. In other words, correspond to the average position along a specific dimension of observations in $points$.</span>\n",
    "\n",
    "**Test your function and check that is works by using the ndarray TEST**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test variables do not change the values\n",
    "TEST = np.array([[1,2,3,4,5],[0,0,1,1,1],[0,1,2,4,5]])\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Write a function <b>cupdate</b> that takes two input arguments: <i>points</i> and <i>clusters</i><br> \n",
    "\n",
    "The argument <i>points</i> is a ndarray containing the coordinates of a set of points (1 point per row).<br>\n",
    "\n",
    "The argument <i>clusters</i> is a 1-dimensional ndarray that indicates the cluster to which each point is associated.<br>\n",
    "\n",
    "Note that values in <i>clusters</i> are integers and can only take values between 0 and K-1, where K is the total number of clusters.\n",
    "\n",
    "The function <b>cupdate</b> should return an ndarray with the average coordinates of the points associated to each cluster, that is the centroid of each cluster. The returned array should have the same number of columns as points (dimensions) and length K (rows).\n",
    "\n",
    "**Test your function and report the centroids generated by passing p and c as inputs with k = 3. Save these centroids as a variable: cen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesst variables, do not change the values\n",
    "p = np.array([[0.8922063, 0.26672425],[0.34475611, 0.35976697],[0.33253499, 0.18923898],[0.66872466, 0.46248986],[0.72823733, 0.10537784],[0.40903598, 0.70639412],[0.79926596, 0.90095583],[0.67886544, 0.84573289],[0.3641813, 0.64296743],[0.07461196, 0.74290527]])\n",
    "c = np.array([2, 0, 0, 1, 1, 0, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "\n",
    "Write a function <b>pupdate</b> that takes two input arguments: $points$ and $centroids$.<br>\n",
    "\n",
    "The function <b>pupdate</b> should return a one-dimensiona ndarray that indicates the index of the centroid that is closer to each point. To determine the distance between a centroid and a point you can use your distance function you created earlier. <br>\n",
    "\n",
    "You will need to assess the distance between each point to each centroid. Different approaches can be taken to do this. For instance, you can start by computing a d by k distance matrix matrix between each of the $d$ points and the $k$ centroids.\n",
    "\n",
    "**Test your function by calling it and passing the array p (as defined above) with the output of cupdate, cen, as arguments. You should get an output that looks like c defined above (but is not exactly the same, can you see why). Print this result and save it in a variable called new_clusters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "Write a function <b>error</b> that takes two input arguments: oldcentroids and newcentroids.<br>\n",
    "\n",
    "The argument oldcentroids corresponds to a ndarray with centroid positions from the previous iteration, and newcentroids to a ndarray with the newly computed centroid positions from the current iteration. <br>\n",
    "\n",
    "The function <b>error</b> should return the average euclidian distance (the square error) between the old and new positions of each centroid.  This will give us a quantity that tell us whether our algorithm is still converging to the solution or  got to good approximation.</span> We will use the function error to obtain an estimate of whether the algorithm is still converging to the solution (that is the centroids are, in average, moving a lot) or if we entered a scenario of small steps (that is the centroids are, in average, not moving that much). \n",
    "\n",
    "We will use this information combined with a **tolerance threshold** in regards to the average change in the centroids positions to decide if it is a good time to stop the algorithm. You should make this decision.\n",
    "\n",
    "\n",
    "**Test your function then report the distance between the centroids calculated in Step 5, cen, and the centroids that you can calculate using the function cupdate with the arguments points and new_clusters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "\n",
    "Write a wrapper function called <b>kmeans</b> that takes the following arguments:\n",
    "- $points$, which is a ndarray of points;\n",
    "- $K$, the number of clusters, set the default value to two;\n",
    "- $niter$, the number of iterations;\n",
    "- $tol$, the error tolerance threshold below which your algorithm should stop\n",
    "\n",
    "The function should return:\n",
    "- A one dimensional ndarray with the cluster of associated to each point,\n",
    "- A ndarray with the location of the K centroids.\n",
    "\n",
    "Use the functions you prepared in the previous to assemble the function <b>kmeans</b>. <br>\n",
    "Use the tolerance as a treshold to stop the algorithm, for instance by evaluating if the average variation in the distance between the new and previous coordinates of the centroids is below the tolerance level. If yes, then you can stop the algorithm and return the outputs. <br>\n",
    "\n",
    "**You will need to make some decisions about the best approach to select the correct range of values to pass to init(). Explain how you did it.**\n",
    "\n",
    "**Note: A common issue with the K-means algorithm is that in some limiting conditions it might lead to empty clusters. In that case it is expected that your algorithm to return errors. Although that is not expected to happen with the examples provided, you might want to consider implementing some heuristics to overcome those errors. However, such is an optional task, and for this homework if you bump into such errors we recommend you try to rerun your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is useful to visually inspect the results in order to assess the performance of the clustering algorthim. <br>\n",
    "Below is an example of how you can visualize your results for a sample dataset. <br>\n",
    "Can you adapt the code to show your results applied to data_test with K = 2, niter = 500, tol = 0.00001.\n",
    "\n",
    "<span style=\"color:red\">**In this step feel free to use any other visualization library such as Seaborn.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boilerplate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "# let us define the style of the plot here\n",
    "style.use('ggplot')\n",
    "colors = [\"g\",\"r\",\"c\",\"b\"]\n",
    "\n",
    "# sample data for this example\n",
    "p = np.array([[0.8922063, 0.26672425],[0.34475611, 0.35976697],[0.33253499, 0.18923898],[0.66872466, 0.46248986],[0.72823733, 0.10537784],[0.40903598, 0.70639412],[0.79926596, 0.90095583],[0.67886544, 0.84573289],[0.3641813, 0.64296743],[0.07461196, 0.74290527]])\n",
    "centroids = [np.array([0.46519213, 0.76779111]),np.array([0.59329188, 0.27671958])]\n",
    "clusters = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0])\n",
    "\n",
    "# plot each point in the centroids array\n",
    "for centroid in centroids:\n",
    "    plt.scatter(centroid[0],centroid[1], marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
    "\n",
    "# plot each point in the points array, colored according to the cluster they belong\n",
    "for i in range(len(clusters)):\n",
    "    plt.scatter(p[i,0],p[i,1], marker=\"x\", color=colors[clusters[i]], s=150, linewidths=5)\n",
    "\n",
    "# plot all elements\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9\n",
    "\n",
    "Write a function <b>inertia</b> that takes three input arguments: $points$, $clusters$, and $centroids$.<br>\n",
    "Where $points$ is a 2-dimensional ndarray with the coordinates of each point in your dataset, clusters is a vector that indicates the cluster of each point (takes values between $0$ and $K-1$), and $centroids$ is a 2-dimensional ndarray with length $k$ of the coordinates of the centroids.\n",
    "\n",
    "The function should return a tuple in which the first value is the number of clusters and the second is the computed **average squared Euclidean distance** of the points to the centroid of the cluster they are assigned.\n",
    "The Squared of the Euclidean distance is a common measure of error that satisfies several important properties, namely it is strictly convex and smooth. It is often used in the method of Least Squares to fit linear functions to data, in which we try to find the parameters of a linear model that minimize the average of the square distances between the observed values and the values predicted by the fitted model. Here we are borrowing these concepts to measure the dispersion of points in a cluster, in other words, the error between the position of the centroid and the locations of the points associated with it.\n",
    "\n",
    "**Test your function and report the results of using point=p, clusters=c, and centroids=cen. These are the variables that you have used in the previous steps**\n",
    "\n",
    "<span style=\"color:red\">**Note: distance always refers to the euclidean distance.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10\n",
    "\n",
    "Load the data from file https://www.dropbox.com/s/wco3lxgn1f4a5k2/data_custering.csv?dl=1 into numpy array.<br>\n",
    "The data consists of the coordinates of $N$ points in a 2-dimensional space. <br>\n",
    "Use the functions <b>kmeans</b> and <b>internia</b> to identify the most suitable number of clusters. <br>\n",
    "You might want to consider doing some visual inspection and reporting. <br>\n",
    "For instance, inspect visually the dataset before performing the clustering; report the inertia values as a line plot; show the result of your clustering.\n",
    "\n",
    "***Tip: use the output of inertia to perform the elbow method https://en.wikipedia.org/wiki/Elbow_method_(clustering).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
